{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports needed\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Contents\n",
    "\n",
    "Upon inspection of the csv file, we see it is ordered and split into 5 columns, from left to right these columns are:\n",
    "\n",
    "* Sepal Length\n",
    "* Sepal Width\n",
    "* Petal Length\n",
    "* Petal Width\n",
    "* Species(setosa, versicolor, virginica)\n",
    "    \n",
    "It is important to determine and split your data according to your needs. For this repo we aim to feed data to a model to train and later test for accuracy. On this basis we will first recognize that the first four bullet points: sepal and petal width and lengts are our inputs and species is our output. \n",
    "\n",
    "Essentially\n",
    "1. x =  Sepal Length, Sepal Width, Petal Length, Petal Width.\n",
    "2. y =  Species(setosa, versicolor, virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data file found at https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv\n",
    "#Edited in Notepad++ to delete first row\n",
    "#Reads first 150 lines of csv file into list\n",
    "iriss = list(csv.reader(open('C:\\\\users\\\\Damian Curran\\\\Desktop\\\\IRIS2.csv')))[0:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Know your training and testing data sets\n",
    "\n",
    "We are working with a single data set which acts as both our train and test sets. During our inspection above we saw the data set is ordered, not exactly what we want for training.\n",
    "\n",
    "We must now first shuffle the data set randomly and then seperate the data to input and output. Note seperating the data first and then shuffling is not a good idea as the data won't be lined up with its original flower type.\n",
    "\n",
    "We are just as lucky, numpy comes with a shuffle function, happy days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifys sequences by shuffling\n",
    "#https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.shuffle.html\n",
    "np.random.shuffle(iriss)\n",
    "\n",
    "#Spliting first four columns\n",
    "irisTrainData = np.array(iriss[0:][:100])[:,:4].astype(np.float)\n",
    "irisTestData = np.array(iriss[100:][:150])[:,:4].astype(np.float)\n",
    "\n",
    "#Splits last column\n",
    "irisTrainType = np.array(iriss[0:][:100])[:,4:].astype('S15')\n",
    "irisTestType = np.array(iriss[100:][:150])[:,4:].astype('S15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our model\n",
    "\n",
    "Now to create our model, note that no data is being fed in here, this is just a model for later use.\n",
    "\n",
    "Lets define some parts here:\n",
    "* Placeholder: somewhere to feed data, won't change\n",
    "* Variable: something python knows it can change\n",
    "* Matmul: numpy matrix multiplication function\n",
    "* Argmax: tensorflow function to get largest index across an axis\n",
    "* tf.nn.softmax_cross_entropy_with_logits: tensorflow function which calculates cross_entropy after applying softmax\n",
    "* cross_entopy: helps in computing the cost of a softmax layer\n",
    "* softmax: normalizes data, it \"squishes\" the data so the sum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes as many values of size 4, it is size four because we feed it:\n",
    "#Sepal Length, Sepal Width, Petal Length, Petal Width.\n",
    "x = tf.placeholder(tf.float32, [None, 4])\n",
    "\n",
    "#this will hold the ouputs, (setosa, versicolor, virginica)\n",
    "y = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "#this represents the index of species types, we'll see more of this later in the code\n",
    "y_true_cls = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "#These are changed to pythons liking to more accurately adjust towards the correct output\n",
    "weights = tf.Variable(tf.zeros([4, 3]))\n",
    "biases = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "#stores the unscaled matrix multiplication into \"logits\"\n",
    "logits = tf.matmul(x, weights) + biases\n",
    "\n",
    "#saves normalized data into y_pred\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "#gets largest index e.g [1,3,2] largest index = 1\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "#can seperate out softmax and cross_entropy\n",
    "#using this function is more accurate, and less lines of code, every line counts\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                        labels=y)\n",
    "\n",
    "#computes the mean of elements across a tensor\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#every tensorflow program uses an optimizer, the most used one is GradientDescent\n",
    "#https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)\n",
    "\n",
    "#tf.equal returns bools(true, false) and stores in correct_prediction\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "#we then cast correct_prediction to a float which returns 0 if false and 1 if true \n",
    "#we then use reduce_mean function to find avrage\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring data\n",
    "\n",
    "Here we convert our labels from categorical data to numerical data uing one-hot encoding.\n",
    "\n",
    "We do this because it  would be improper to say setosa = 1 and versicolor = 2, that would mean veriscolor is greater than setosa which is not true.\n",
    "\n",
    "There are many ways to do this, for this example I will be using the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This converts setosa to a one-hot vector [1,0,0]\n",
    "trainTypeHot = pd.get_dummies(irisTrainType.ravel())\n",
    "testTypeHot = pd.get_dummies(irisTestType.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start our session\n",
    "\n",
    "A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "#Initializes all previous mentioned variables\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to call for training model, accepts paramaters of type num_iterations, which deifines how many times to loop\n",
    "def optimize(num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        #data is fed into model using this construct\n",
    "        feed_dict_train = {x: irisTrainData,\n",
    "                           y: trainTypeHot}\n",
    "        \n",
    "        #calls session.run and runs model method to begin training\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
